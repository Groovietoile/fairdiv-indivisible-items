{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Protocols for Fair Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import Problem\n",
    "import fairness_measures\n",
    "#import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several protocols have been implemented. They can be accessed by importing the module protocols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 8, 'r5': 1}\n",
      "agent 2{'r0': 2, 'r1': 3, 'r2': 9, 'r3': 1, 'r4': 2, 'r5': 3}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p0 = Problem(3,6,'empty', centralized=True)\n",
    "p0.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':8,'r5':1},\\\n",
    "{'r0':2,'r1':3,'r2':9,'r3':1,'r4':2,'r5':3}])\n",
    "print (p0)\n",
    "print (p0.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0.343, 'r1': 0.245, 'r2': 0.23, 'r3': 0.181}\n",
      "agent 2{'r0': 0.03, 'r1': 0.271, 'r2': 0.677, 'r3': 0.023}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1 = Problem(3,4,'normalized',centralized=True)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r3', 'r4']\t11\n",
      "agent  2           ['r0', 'r1', 'r2', 'r5']\t17\n",
      "\n",
      "[(1.5, 'r1'), (2.0, 'r0'), (1.8, 'r2'), (3.0, 'r5')]\n",
      "Resource  r1  moves from  2  to  1\n",
      "Resource  r2  will be splitted!\n",
      "Agent  1  gets  0.071  of resource  r2\n",
      "Both agents get utility: 13.355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13.355, 'r2', 1, 0.07142857142857142)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.adjustedWinner(p0,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you understand exactly why items are allocated this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Manipulating Adjusted Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 75, 'r1': 25}\n",
      "agent 2{'r0': 25, 'r1': 75}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2 = Problem(3,2,'uniform',centralized=True)\n",
    "p2.setUtilities(\n",
    "[{'r0':0,'r1':0},\\\n",
    "{'r0':75,'r1':25},\\\n",
    "{'r0':25,'r1':75}]\n",
    ")\n",
    "print (p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, the output of the adjusted winner protocol is rather obvious. Each agent gets its preferred item and everyone enjoys 75 of utility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                             ['r0']\t75\n",
      "agent  2                             ['r1']\t75\n",
      "\n",
      "[(3.0, 'r1')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(75, 'r1', 1, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocols.adjustedWinner(p2,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can you find a **manipulation** for agent 1, that is, a way to misrepresent the preferences of the agent (in other words, announce a valuation for an item which differs from the real one) such that the utility is in reality higher? \n",
    "Note that you will need to compute the allocation with the **declared** preferences, but that the actual utility enjoyed by agents must be computed with their **true** preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output allocation phase:\n",
      "auctioneer                                  []\t\n",
      "agent  1                             ['r0']\t26\n",
      "agent  2                             ['r1']\t75\n",
      "\n",
      "[(1.014, 'r1')]\n",
      "Resource  r1  will be splitted!\n",
      "Agent  1  gets  0.329  of resource  r1\n",
      "Both agents get utility: 50.346000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50.346000000000004, 'r1', 1, 0.3288590604026846)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = Problem(3,2,'uniform',centralized=True)\n",
    "p2.setUtilities(\n",
    "[{'r0':0,'r1':0},\\\n",
    "{'r0':26,'r1':74},\\\n",
    "{'r0':25,'r1':75}]\n",
    ")\n",
    "protocols.adjustedWinner(p2,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the \"best\" manipulation that agent 1 can do? \n",
    "To evaluate this, it will be useful to run a script trying all the different values possibly announced by agent 1, and to plot the utility obtained with each of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.32, 'r1')]\n",
      "[(1.307, 'r1')]\n",
      "[(1.293, 'r1')]\n",
      "[(1.28, 'r1')]\n",
      "[(1.267, 'r1')]\n",
      "[(1.253, 'r1')]\n",
      "[(1.24, 'r1')]\n",
      "[(1.227, 'r1')]\n",
      "[(1.213, 'r1')]\n",
      "[(1.2, 'r1')]\n",
      "[(1.187, 'r1')]\n",
      "[(1.173, 'r1')]\n",
      "[(1.16, 'r1')]\n",
      "[(1.147, 'r1')]\n",
      "[(1.133, 'r1')]\n",
      "[(1.12, 'r1')]\n",
      "[(1.107, 'r1')]\n",
      "[(1.093, 'r1')]\n",
      "[(1.08, 'r1')]\n",
      "[(1.067, 'r1')]\n",
      "[(1.053, 'r1')]\n",
      "[(1.04, 'r1')]\n",
      "[(1.027, 'r1')]\n",
      "[(1.013, 'r1')]\n",
      "[(1.0, 'r0'), (1.0, 'r1')]\n",
      "[(1.014, 'r1')]\n",
      "[(1.027, 'r1')]\n",
      "[(1.042, 'r1')]\n",
      "[(1.056, 'r1')]\n",
      "[(1.071, 'r1')]\n",
      "[(1.087, 'r1')]\n",
      "[(1.103, 'r1')]\n",
      "[(1.119, 'r1')]\n",
      "[(1.136, 'r1')]\n",
      "[(1.154, 'r1')]\n",
      "[(1.172, 'r1')]\n",
      "[(1.19, 'r1')]\n",
      "[(1.21, 'r1')]\n",
      "[(1.23, 'r1')]\n",
      "[(1.25, 'r1')]\n",
      "[(1.271, 'r1')]\n",
      "[(1.293, 'r1')]\n",
      "[(1.316, 'r1')]\n",
      "[(1.339, 'r1')]\n",
      "[(1.364, 'r1')]\n",
      "[(1.389, 'r1')]\n",
      "[(1.415, 'r1')]\n",
      "[(1.442, 'r1')]\n",
      "[(1.471, 'r1')]\n",
      "[(1.5, 'r1')]\n",
      "[(1.531, 'r1')]\n",
      "[(1.562, 'r1')]\n",
      "[(1.596, 'r1')]\n",
      "[(1.63, 'r1')]\n",
      "[(1.667, 'r1')]\n",
      "[(1.705, 'r1')]\n",
      "[(1.744, 'r1')]\n",
      "[(1.786, 'r1')]\n",
      "[(1.829, 'r1')]\n",
      "[(1.875, 'r1')]\n",
      "[(1.923, 'r1')]\n",
      "[(1.974, 'r1')]\n",
      "[(2.027, 'r1')]\n",
      "[(2.083, 'r1')]\n",
      "[(2.143, 'r1')]\n",
      "[(2.206, 'r1')]\n",
      "[(2.273, 'r1')]\n",
      "[(2.344, 'r1')]\n",
      "[(2.419, 'r1')]\n",
      "[(2.5, 'r1')]\n",
      "[(2.586, 'r1')]\n",
      "[(2.679, 'r1')]\n",
      "[(2.778, 'r1')]\n",
      "[(2.885, 'r1')]\n",
      "[(3.0, 'r1')]\n",
      "[(3.04, 'r0')]\n",
      "[(3.08, 'r0')]\n",
      "[(3.12, 'r0')]\n",
      "[(3.16, 'r0')]\n",
      "[(3.2, 'r0')]\n",
      "[(3.24, 'r0')]\n",
      "[(3.28, 'r0')]\n",
      "[(3.32, 'r0')]\n",
      "[(3.36, 'r0')]\n",
      "[(3.4, 'r0')]\n",
      "[(3.44, 'r0')]\n",
      "[(3.48, 'r0')]\n",
      "[(3.52, 'r0')]\n",
      "[(3.56, 'r0')]\n",
      "[(3.6, 'r0')]\n",
      "[(3.64, 'r0')]\n",
      "[(3.68, 'r0')]\n",
      "[(3.72, 'r0')]\n",
      "[(3.76, 'r0')]\n",
      "[(3.8, 'r0')]\n",
      "[(3.84, 'r0')]\n",
      "[(3.88, 'r0')]\n",
      "[(3.92, 'r0')]\n",
      "[(3.96, 'r0')]\n",
      "[(4.0, 'r0')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vérification avec un script qui essaye toutes les valeurs possibles annoncées par l'agent 1\n",
    "# prend en paramètre les vraies utilités de r0 et r1 pour l'agent 1\n",
    "# (les utilités pour l'agent 2 sont considérées comme fixes)\n",
    "\n",
    "def manipulation_a1(vraie_utilite_r0, vraie_utilite_r1):\n",
    "\n",
    "    y = []\n",
    "    \n",
    "    for i in range(100):\n",
    "        \n",
    "        pb = Problem(3, 2, 'uniform', centralized = True)\n",
    "        \n",
    "        utilites = [{'r0':0,'r1':0},\\\n",
    "                {'r0':i+1,'r1':(100-i-1)},\\\n",
    "                {'r0':25,'r1':75}]\n",
    "        \n",
    "        pb.setUtilities(utilites)\n",
    "        \n",
    "        u, r, low, part_of_low = protocols.adjustedWinner(pb,verbose=False)\n",
    "\n",
    "        # l'agent 2 a moins d'utilité que l'agent 1\n",
    "        if low == 2: \n",
    "            # r = ressource à partager\n",
    "            if r=='r0':\n",
    "                y.append(vraie_utilite_r1 * (1-part_of_low))\n",
    "\n",
    "            else:\n",
    "                y.append(vraie_utilite_r0 * (1-part_of_low))\n",
    "        else:\n",
    "            y.append(vraie_utilite_r1 + part_of_low * vraie_utilite_r0) \n",
    "\n",
    "    x = np.arange(100)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# Affichage de l'utilité obtenue par l'agent 1 pour toutes les valeurs possibles annoncées par l'agent 1\n",
    "\n",
    "x, y = manipulation_a1(25, 75)\n",
    "xmax = x[np.argmax(y)]\n",
    "ymax = y[np.argmax(y)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x887250>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('Valuation of item 1')\n",
    "ax.set_ylabel('Total score according to true valuation')\n",
    "\n",
    "plt.vlines(x=xmax, ymin=0, ymax=ymax, color='red')\n",
    "plt.hlines(xmin=0, xmax=xmax, y=ymax, color='red')\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 2 Picking Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p3 = Problem(4,6,'empty', centralized=True)\n",
    "p3.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print (p3)\n",
    "print (p3.printAllocation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us apply a picking sequence on our problem p3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  1  picks  r4\n",
      "agent  2  picks  r2\n",
      "agent  3  picks  r0\n",
      "agent  2  picks  r1\n",
      "agent  3  picks  r3\n",
      "agent  1  picks  r5\n"
     ]
    }
   ],
   "source": [
    "s0 = [1,2,3,2,3,1]\n",
    "protocols.pickingSequence(p3,s0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctioneer                                  []\t\n",
      "agent  1                       ['r4', 'r5']\t 9\n",
      "agent  2                       ['r2', 'r1']\t14\n",
      "agent  3                       ['r0', 'r3']\t 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p3.printAllocation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(fairness_measures.envyMatrix(p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to generate standard sequences, like balanced or alternate ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "s= protocols.generateSequence(3,6,'balanced')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is the fairest picking sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider 3 agents and 5 items. Can you propose some sequence which would do well in terms of egalitarian social welfare? You can simulate a number of picking sequences by specifying: the number of experiments, the number of agents (remember to count agent 0 here-to be fixed sorry), the number of objects, the sequence, and the ways utilities are generated.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 2.964\n",
      "= Ratio of proportional:                0.201\n",
      "= Ratio of envy free:                     0.07\n",
      "= Average number of envious:              0.93\n",
      "= Average max envy:                      4.293\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,2,2,1,3],'borda',verbose=False) # mauvaise séquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                   5.0\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.274\n",
      "= Average number of envious:             0.826\n",
      "= Average max envy:                      1.056\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,5,[1,3,2,2,3],'borda',verbose=False) # meilleur ESW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to conclude: \n",
    "For 3 agents, and 6 and 8 objects, could you find the fairest picking sequences in terms of: \n",
    "* egalitarian social welfare\n",
    "* average max envy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.493\n",
      "= Ratio of proportional:                0.901\n",
      "= Ratio of envy free:                    0.587\n",
      "= Average number of envious:             0.448\n",
      "= Average max envy:                      1.048\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,1,2,3,1,2],'borda',verbose=False) # to start with a bad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 3, 2, 1]\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 8.353\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.738\n",
      "= Average number of envious:             0.266\n",
      "= Average max envy:                      0.336\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# séquence la plus juste pour 3 agents et 6 objets : [1, 2, 3, 3, 2, 1]\n",
    "# c'est une séquence symétrique où les agents ne choisissent pas deux fois de suite donc on a une séquence équilibrée\n",
    "# et juste pour tous les agents\n",
    "s = protocols.generateSequence(3,6,'balanced')\n",
    "print(s)\n",
    "simulations.simulationPickingSequences(1000,4,6,s,'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.896\n",
      "= Ratio of proportional:                0.968\n",
      "= Ratio of envy free:                    0.727\n",
      "= Average number of envious:             0.282\n",
      "= Average max envy:                      0.571\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                13.899\n",
      "= Ratio of proportional:                0.972\n",
      "= Ratio of envy free:                    0.747\n",
      "= Average number of envious:             0.264\n",
      "= Average max envy:                      0.554\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# séquence la plus juste pour 3 agents et 8 objets : il y en a plusieurs\n",
    "# c'est le même principe ; les agents ne choisissent pas deux fois de suite et choisissent à nouveau une fois que tout\n",
    "# le monde a choisi un même nombre d'objets (dans la limite du nombre d'objets donc ici il y a un agent qui a 1 objet \n",
    "# de moins)\n",
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,3,2,1,2,3],'borda',verbose=False)\n",
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,3,2,1,3,2],'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Lipton et al. protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now test the protocol of Lipton, which allocates items one by one and solves envy cycles when they occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 1{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 2{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "agent 3{'r0': 0, 'r1': 0, 'r2': 0, 'r3': 0, 'r4': 0, 'r5': 0}\n",
      "\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "agent 1{'r0': 1, 'r1': 2, 'r2': 5, 'r3': 3, 'r4': 7, 'r5': 2}\n",
      "agent 2{'r0': 2, 'r1': 6, 'r2': 8, 'r3': 1, 'r4': 1, 'r5': 2}\n",
      "agent 3{'r0': 5, 'r1': 4, 'r2': 4, 'r3': 3, 'r4': 2, 'r5': 2}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Running the Lipton et al. protocol\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "auctioneer ['r0', 'r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                                 []\t 0\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: []}\n",
      "allocating resource  r0\n",
      "auctioneer      ['r1', 'r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                                 []\t 0\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [1], 3: [1]}\n",
      "allocating resource  r1\n",
      "auctioneer            ['r2', 'r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                                 []\t 0\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r2\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r0']\t 1\n",
      "agent  2                             ['r1']\t 6\n",
      "agent  3                             ['r2']\t 4\n",
      "\n",
      "envy graph: {0: [], 1: [2, 3], 2: [3], 3: [1]}\n",
      "solving the cycle: []\n",
      "auctioneer                  ['r3', 'r4', 'r5']\t\n",
      "agent  1                             ['r1']\t 2\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "allocating resource  r3\n",
      "auctioneer                        ['r4', 'r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                             ['r2']\t 8\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [], 2: [], 3: [1]}\n",
      "allocating resource  r4\n",
      "auctioneer                              ['r5']\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                             ['r0']\t 5\n",
      "\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: [1, 2]}\n",
      "allocating resource  r5\n",
      "envy graph: {0: [], 1: [2], 2: [], 3: []}\n",
      "Final allocation:\n",
      "auctioneer                                  []\t\n",
      "agent  1                       ['r1', 'r3']\t 5\n",
      "agent  2                       ['r2', 'r4']\t 9\n",
      "agent  3                       ['r0', 'r5']\t 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p4 = Problem(4,6,'empty','centralized')\n",
    "print(p4)\n",
    "print(p4.printAllocation())\n",
    "p4.setUtilities(\n",
    "[{'r0':0,'r1':0,'r2':0,'r3':0,'r4':0,'r5':0},\\\n",
    "{'r0':1,'r1':2,'r2':5,'r3':3,'r4':7,'r5':2},\\\n",
    "{'r0':2,'r1':6,'r2':8,'r3':1,'r4':1,'r5':2},\\\n",
    "{'r0':5,'r1':4,'r2':4,'r3':3,'r4':2,'r5':2}]\n",
    ")\n",
    "print(p4)\n",
    "\n",
    "protocols.lipton(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Local deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us play a bit with local exchanges. For this, we will need to create a decentralized MARA problem. Items are intially allocated at random among agents. Here, utilities are Borda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 3, 'r1': 5, 'r2': 6, 'r3': 4, 'r4': 1, 'r5': 2}\n",
      "agent 1{'r0': 6, 'r1': 3, 'r2': 5, 'r3': 2, 'r4': 4, 'r5': 1}\n",
      "agent 2{'r0': 1, 'r1': 3, 'r2': 2, 'r3': 5, 'r4': 6, 'r5': 4}\n",
      "agent 3{'r0': 2, 'r1': 1, 'r2': 6, 'r3': 5, 'r4': 3, 'r5': 4}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                                 []\t 0\n",
      "agent  1                             ['r0']\t 6\n",
      "agent  2                       ['r2', 'r4']\t 8\n",
      "agent  3                 ['r1', 'r3', 'r5']\t10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "p5 = Problem(4,6,'borda',centralized=False)\n",
    "print(p5)\n",
    "print(p5.printAllocation())\n",
    "\n",
    "p6 = copy.deepcopy(p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot which agents could perform mutually beneficial deals? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent  1  meets agent  2\n",
      "agent  2  meets agent  3\n",
      "deal between  2  and  3 for  r2  and  r1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                                 []\t 0\n",
      "agent  1                             ['r0']\t 6\n",
      "agent  2                       ['r4', 'r1']\t 9\n",
      "agent  3                 ['r3', 'r5', 'r2']\t15\n",
      "\n",
      "agent  2  meets agent  3\n",
      "agent  1  meets agent  2\n",
      "agent  0  meets agent  1\n",
      "agent  0  meets agent  2\n",
      "agent  1  meets agent  3\n",
      "agent  0  meets agent  3\n",
      "End of dynamics. No more deal possible.\n"
     ]
    }
   ],
   "source": [
    "protocols.randomDynamics(p5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the envy of the final allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 2, 3], 1: [2, 3], 2: [3], 3: []}\n"
     ]
    }
   ],
   "source": [
    "m = fairness_measures.envyMatrix(p5)\n",
    "g = fairness_measures.buildEnvyGraph(m)\n",
    "print (g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Could you find fairer dynamics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, agents just meet randomly (a given pair is picked uniformly among the possible ones). \n",
    "Could you conceive a fairer dynamics and test it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "8\n",
      "10\n",
      "14\n",
      "16\n",
      "18\n",
      "agent  0  meets agent  1\n",
      "agent  0  meets agent  2\n",
      "agent  0  meets agent  3\n",
      "agent  1  meets agent  2\n",
      "agent  1  meets agent  3\n",
      "agent  2  meets agent  3\n",
      "deal between  2  and  3 for  r2  and  r1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                                 []\t 0\n",
      "agent  1                             ['r0']\t 6\n",
      "agent  2                       ['r4', 'r1']\t 9\n",
      "agent  3                 ['r3', 'r5', 'r2']\t15\n",
      "\n",
      "agent  0  meets agent  1\n",
      "agent  0  meets agent  2\n",
      "agent  0  meets agent  3\n",
      "agent  1  meets agent  2\n",
      "agent  1  meets agent  3\n",
      "agent  2  meets agent  3\n",
      "End of dynamics. No more deal possible.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import protocols\n",
    "\n",
    "def fairerDynamics(p,verbose=False):\n",
    "    testedPairs = []\n",
    "    allPairs = [(x,y) for x in range(p.n) for y in range(x,p.n) if x!=y]\n",
    "    #print(allPairs)\n",
    "    allPairsWithU = []\n",
    "    u = 0\n",
    "    for pair in allPairs:\n",
    "        x = pair[0]\n",
    "        y = pair[1]\n",
    "        u = p.agent[x].current_u + p.agent[y].current_u\n",
    "        allPairsWithU.append((x,y,u))\n",
    "        \n",
    "    allPairsWithU = sorted(allPairsWithU, key=itemgetter(2))\n",
    "    \n",
    "    for pair in allPairsWithU:\n",
    "        print(pair[2])\n",
    "    #random.shuffle(allPairs)\n",
    "\n",
    "    while len(testedPairs) != len(allPairs):\n",
    "        candidatePairs = [(x,y,u) for (x,y,u) in allPairsWithU if (x,y,u) not in testedPairs]\n",
    "        #print (testedPairs)\n",
    "        # choice in all pairs - tested\n",
    "        (x,y,u) = candidatePairs[0]\n",
    "        if verbose:\n",
    "            print(\"agent \", x, \" meets agent \",y)\n",
    "\n",
    "        if not(protocols.rationalSwapDeal(p,x,y,verbose)):\n",
    "            testedPairs.append((x,y,u))\n",
    "        else:\n",
    "            testedPairs = []\n",
    "            if verbose:\n",
    "                print (p.printAllocation())\n",
    "    print (\"End of dynamics. No more deal possible.\")\n",
    "\n",
    "\n",
    "fairerDynamics(p6,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 2, 3], 1: [2, 3], 2: [3], 3: []}\n"
     ]
    }
   ],
   "source": [
    "m = fairness_measures.envyMatrix(p6)\n",
    "g = fairness_measures.buildEnvyGraph(m)\n",
    "print (g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: BT protocol with contested pile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code the BT protocol, and return the size of the contested pile, the Borda score of agents as well as whether the allocation is EF under the definition seen during the course. When increasing the number of objects, plot the likelihood of the protocol returning an EF allocation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des ressources triées selon l'utilité de l'agent\n",
    "def BT_name_prefered_items(p):\n",
    "    preferences_A = p.agent[0].u.copy()\n",
    "    preferences_B = p.agent[1].u.copy()\n",
    "    preferences_A = list(dict(sorted(preferences_A.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    preferences_B = list(dict(sorted(preferences_B.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    return preferences_A,preferences_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocation des ressources à partir des préférences des agents\n",
    "def BT_allocation(preferences_A, preferences_B):\n",
    "    contested_pile = []\n",
    "    A = []\n",
    "    B = []\n",
    "    while not(len(preferences_A) == 0 and len(preferences_B) == 0):\n",
    "        \n",
    "        if preferences_A[0] != preferences_B[0]:\n",
    "            A.append(preferences_A[0])\n",
    "            B.append(preferences_B[0])\n",
    "            if preferences_B[0] in preferences_A:\n",
    "                preferences_A.remove(preferences_B[0])\n",
    "            if preferences_A[0] in preferences_B:\n",
    "                preferences_B.remove(preferences_A[0])\n",
    "        else:\n",
    "            contested_pile.append(preferences_A[0])\n",
    "            \n",
    "        preferences_A.remove(preferences_A[0])\n",
    "        preferences_B.remove(preferences_B[0])\n",
    "\n",
    "    return A, B, contested_pile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du protocle BT avec le score de Borda et vérification Envy Free\n",
    "def BT_protocol(p):\n",
    "    \n",
    "    preferences_A, preferences_B = BT_name_prefered_items(p)\n",
    "#     print(\"Preferences A :\", preferences_A)\n",
    "#     print(\"Preferences B :\", preferences_B)\n",
    "    \n",
    "    bundle_A, bundle_B, contested_pile = BT_allocation(preferences_A.copy(), preferences_B.copy())\n",
    "#     print(\"Bundle A :\", bundle_A)\n",
    "#     print(\"Bundle B :\", bundle_B)\n",
    "#     print(\"Contested pile :\", contested_pile)\n",
    "    \n",
    "    # convert bundles to allocations\n",
    "    bundles = [bundle_A, bundle_B]\n",
    "    allocation = []\n",
    "    \n",
    "    for i in range(len(p.agent)):\n",
    "        allocation.append([0]*p.m)\n",
    "        for j in range(len(bundles[i])):\n",
    "            #print(int(bundles[i][j].split(\"r\")[1]))\n",
    "            allocation[i][int(bundles[i][j].split(\"r\")[1])] = 1\n",
    "    \n",
    "    #print(allocation)\n",
    "    p.setAllocation(allocation)\n",
    "    #print(p.printAllocation())\n",
    "    \n",
    "    size_contested_pile = len(contested_pile)\n",
    "\n",
    "    # score de Borda\n",
    "    borda_score = []\n",
    "    preferences = [preferences_A, preferences_B]\n",
    "    for i in range(len(p.agent)):\n",
    "        borda_score.append(0)\n",
    "        for j in range(len(bundles[i])):\n",
    "            borda_score[-1] += len(preferences[i]) - preferences[i].index(bundles[i][j]) - 1\n",
    "    \n",
    "    em = fairness_measures.envyMatrix(p)\n",
    "    #print(em)\n",
    "    #print(\"There are \", fairness_measures.nbEnviousAgents(em), \" envious agents\")\n",
    "    #print(\"The maximum envy among two agents is \", fairness_measures.maxEnvy(em))\n",
    "    is_EF = fairness_measures.isEnvyFree(em)\n",
    "    \n",
    "    return size_contested_pile, borda_score[0], borda_score[1], is_EF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retourne les axes pour plot l'évolution du ratio EF en fonction du nb d'objets\n",
    "def plot_likelihood(nb_objects, nb_iterations):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(1,nb_objects):\n",
    "        cpt = 0\n",
    "        for j in range(nb_iterations):\n",
    "            p = Problem(2,i,'borda',centralized=False)\n",
    "            size_contested_pile, borda_score_a, borda_score_b, is_EF = BT_protocol(p)\n",
    "            if is_EF:\n",
    "                cpt += 1\n",
    "        x.append(i)\n",
    "        y.append(cpt/nb_iterations)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0{'r0': 5, 'r1': 2, 'r2': 3, 'r3': 4, 'r4': 1}\n",
      "agent 1{'r0': 5, 'r1': 2, 'r2': 3, 'r3': 1, 'r4': 4}\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "agent  0                       ['r1', 'r2']\t 5\n",
      "agent  1                 ['r0', 'r3', 'r4']\t10\n",
      "\n",
      "Preferences A : ['r0', 'r3', 'r2', 'r1', 'r4']\n",
      "Preferences B : ['r0', 'r4', 'r2', 'r1', 'r3']\n",
      "Bundle A : ['r3']\n",
      "Bundle B : ['r4']\n",
      "Contested pile : ['r0', 'r2', 'r1']\n",
      "taille de contested pile =  3\n",
      "utilité agent A =  3\n",
      "utilité agent B =  3\n",
      "EF =  True\n"
     ]
    }
   ],
   "source": [
    "p_bt = Problem(2,5,'borda',centralized=False)\n",
    "print(p_bt)\n",
    "print(p_bt.printAllocation())\n",
    "\n",
    "temp = BT_protocol(p_bt)\n",
    "print(\"taille de contested pile = \", temp[0])\n",
    "print(\"utilité agent A = \", temp[1])\n",
    "print(\"utilité agent B = \", temp[2])\n",
    "print(\"EF = \", temp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nb_objects = 50\n",
    "nb_iterations = 100\n",
    "x,y = plot_likelihood(nb_objects,nb_iterations)\n",
    "\n",
    "plt.title(\"Evolution du ratio EF en fonction du nb d'objets\")\n",
    "plt.xlabel(\"Nombre d'objets\")\n",
    "plt.ylabel(\"% Envy Free\")\n",
    "plt.plot(x, y, c=\"purple\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The discussion and example about Adjusted Winner Manipulation is taken from a video by Eric Pacuit: \n",
    "https://www.youtube.com/watch?v=RtcnSXL69NQ\n",
    "\n",
    "* See (Bouveret and Lang, IJCAI-11) for more details about picking sequences. \n",
    "\n",
    "* See https://www.ams.org/notices/201402/rnoti-p130.pdf for the description of the BT protocol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notebook last updated 2022-01-17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions du cours\n",
    "\n",
    "* 2 agents: which sequence gives the better ESW on average ? A: [122121] B: [121221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A :\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                 12.36\n",
      "= Ratio of proportional:                0.956\n",
      "= Ratio of envy free:                    0.956\n",
      "= Average number of envious:             0.044\n",
      "= Average max envy:                      0.044\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "B :\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                12.376\n",
      "= Ratio of proportional:                0.955\n",
      "= Ratio of envy free:                    0.955\n",
      "= Average number of envious:             0.045\n",
      "= Average max envy:                      0.045\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# En relançant à plusieurs reprises les simulations avec 2 agents et les séquences A et B, on observe un ESW moyen\n",
    "# équivalent pour les deux séquences.\n",
    "\n",
    "print(\"A :\")\n",
    "simulations.simulationPickingSequences(1000,3,6,[1,2,2,1,2,1],'borda',verbose=False) # séquence A\n",
    "\n",
    "print(\"B :\")\n",
    "simulations.simulationPickingSequences(1000,3,6,[1,2,1,2,2,1],'borda',verbose=False) # séquence B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3 agents and 5 goods: which sequence has highest ratio of PROP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                   5.0\n",
      "= Ratio of proportional:                  1.0\n",
      "= Ratio of envy free:                    0.302\n",
      "= Average number of envious:             0.777\n",
      "= Average max envy:                      1.028\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# La séquence suivante a le meilleur ratio PROP. En effet, avec une séquence symétrique, on a ici par exemple l'agent 3 qui\n",
    "# a choisi en dernier \"au premier tour\" puis il peut choisir en premier \"au second tour\" ce qui permet de ne pas favoriser\n",
    "# en particulier un des agents.\n",
    "\n",
    "simulations.simulationPickingSequences(1000,4,5,[1,2,3,3,2],'borda',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3 agents and 8 goods: which sequence has highest ratio of EF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                14.011\n",
      "= Ratio of proportional:                0.964\n",
      "= Ratio of envy free:                    0.758\n",
      "= Average number of envious:             0.251\n",
      "= Average max envy:                      0.478\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "= Number of experiments:                 1000\n",
      "= Average egalitarian sw:                14.078\n",
      "= Ratio of proportional:                0.976\n",
      "= Ratio of envy free:                    0.777\n",
      "= Average number of envious:             0.233\n",
      "= Average max envy:                      0.438\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# meilleur ratio EF trouvé :\n",
    "\n",
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,3,2,1,1,2],'borda',verbose=False)\n",
    "simulations.simulationPickingSequences(1000,4,8,[1,2,3,3,2,1,2,1],'borda',verbose=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
